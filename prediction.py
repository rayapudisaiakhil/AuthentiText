from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from scipy.sparse import hstack
import re
import pandas as pd
from text_processing_functions import text_preprocessing
import joblib
import sys
import pickle

tfidf_vectorizer = TfidfVectorizer()
scaler = StandardScaler()


def feat_gen(text):
    # Preprocess the input text
    features = text_preprocessing(text)

    # Create a DataFrame for the single observation
    features_df = pd.DataFrame([features])
    # Reorder the columns based on the specified order
    features_df = features_df[['verb_count', 'vocab_richness', 'GPE', 'punctuation_percentage', 'ORG',
                               'CARDINAL', 'DATE', 'sentiment_polarity', 'readability', 'TIME',
                               'sentence_length', 'sentiment_subjectivity', 'cleaned_text']]


    return features_df


def load_model(model_file_path, tfidf_vectorizer_file_path, scaler_file_path):
    # Load the trained model
    with open(model_file_path, 'rb') as model_file:
        model = pickle.load(model_file)

    # Load the TF-IDF vectorizer
    with open(tfidf_vectorizer_file_path, 'rb') as tfidf_file:
        tfidf_vectorizer = pickle.load(tfidf_file)

    # Load the scaler
    with open(scaler_file_path, 'rb') as scaler_file:
        scaler = pickle.load(scaler_file)

    return model, tfidf_vectorizer, scaler

# def predict_label_and_extract_tfidf_words_colored(essay_text, model, tfidf_vectorizer, scaler):
#     # Generate features for the input essay
#     features_df = feat_gen(essay_text)

#     # Separate text and numerical features
#     essay_text_tfidf = tfidf_vectorizer.transform(features_df['cleaned_text'])
#     essay_numeric_scaled = scaler.transform(features_df.drop(columns=['cleaned_text']))

#     # Concatenate TF-IDF vectors with scaled numerical features
#     essay_processed = hstack([essay_numeric_scaled, essay_text_tfidf])

#     # Predict label using the trained model
#     predicted_label = model.predict(essay_processed)

#     # Extract important TF-IDF words
#     # Get feature names from TF-IDF vectorizer
#     feature_names = tfidf_vectorizer.get_feature_names_out()

#     # Get TF-IDF scores for each word in the essay text
#     tfidf_scores = essay_text_tfidf.toarray()[0]  # Assuming essay_processed has only one row

#     # Create a dictionary mapping feature names to their TF-IDF scores
#     feature_tfidf_scores = dict(zip(feature_names, tfidf_scores))

#     # Sort the features by their TF-IDF scores in descending order
#     sorted_features = sorted(feature_tfidf_scores.items(), key=lambda x: x[1], reverse=True)

#     # Return the top N most important words
#     top_n = 10
#     important_words = [word for word, score in sorted_features[:top_n]]

#     # Output the predicted label
#     if predicted_label == 0:
#         label = "The essay is written by a human."
#         color = 'lightgreen'  # HTML color for green
#     else:
#         label = "The essay is generated by AI."
#         color = 'lightcoral'  # HTML color for red

#     # Highlight the top occurring words in the text
#     for word in important_words:
#         essay_text = re.sub(f'\\b{word}\\b', f'<mark style="background-color: {color}">{word}</mark>', essay_text, flags=re.IGNORECASE)

#     return label, important_words, essay_text

def predict_label_and_extract_tfidf_words_colored(essay_text, model, tfidf_vectorizer, scaler):
    # Generate features for the input essay
    total_word_count = len(essay_text.split())

    features_df = feat_gen(essay_text)

    # Separate text and numerical features
    essay_text_tfidf = tfidf_vectorizer.transform(features_df['cleaned_text'])
    essay_numeric_scaled = scaler.transform(features_df.drop(columns=['cleaned_text']))

    # Concatenate TF-IDF vectors with scaled numerical features
    essay_processed = hstack([essay_numeric_scaled, essay_text_tfidf])

    # Predict label using the trained model
    predicted_label = model.predict(essay_processed)

    # Extract important TF-IDF words
    # Get feature names from TF-IDF vectorizer
    feature_names = tfidf_vectorizer.get_feature_names_out()

    # Get TF-IDF scores for each word in the essay text
    tfidf_scores = essay_text_tfidf.toarray()[0]  # Assuming essay_processed has only one row

    # Create a dictionary mapping feature names to their TF-IDF scores
    feature_tfidf_scores = dict(zip(feature_names, tfidf_scores))

    # Sort the features by their TF-IDF scores in descending order
    sorted_features = sorted(feature_tfidf_scores.items(), key=lambda x: x[1], reverse=True)

    # Return the top N most important words
    top_n = 10
    important_words = [word for word, score in sorted_features[:top_n]]

    # Calculate feature values
    # feature_values = {
    #     'verb_count': features_df['verb_count'].values[0],
    #     'vocab_richness': features_df['vocab_richness'].values[0],
    #     'punctuation_percentage': features_df['punctuation_percentage'].values[0],
    #     # Add more features as needed
    # }
    feature_values = {
                'verb_percentage': (features_df['verb_count'].values[0] / total_word_count) * 100 if total_word_count > 0 else 0,
                'vocab_richness': features_df['vocab_richness'].values[0] * 100,  # Assuming this is a ratio, convert to percentage
                'punctuation_percentage': features_df['punctuation_percentage'].values[0] * 100,  # Assuming this is already a percentage
                # Add more features as needed
            }

    # Output the predicted label
    if predicted_label == 0:
        label = "The essay is written by a human."
        color = 'lightgreen'  # HTML color for green
    else:
        label = "The essay is generated by AI."
        color = 'lightcoral'  # HTML color for red

    # Highlight the top occurring words in the text
    for word in important_words:
        essay_text = re.sub(f'\\b{word}\\b', f'<mark style="background-color: {color}">{word}</mark>', essay_text, flags=re.IGNORECASE)

    return label, important_words, essay_text, feature_values




if __name__ == "__main__":
    # Ensure proper usage
    if len(sys.argv) != 2:
        print("Usage: python prediction.py <input_text>")
        sys.exit(1)

    input_text = sys.argv[1]

    # Define the file paths for the saved model and other necessary objects
    model_file_path = 'random_forest_model.pkl'
    tfidf_vectorizer_file_path = 'tfidf_vectorizer.pkl'
    scaler_file_path = 'scaler.pkl'

    # Load the trained model, TF-IDF vectorizer, and scaler
    model, tfidf_vectorizer, scaler = load_model(model_file_path, tfidf_vectorizer_file_path, scaler_file_path)

    # Make predictions
    label, important_words, highlighted_text = predict_label_and_extract_tfidf_words_colored(input_text, model, tfidf_vectorizer, scaler)

    # Print the predicted label and highlighted text
    print(label)
    # print("Important words:", important_words)
    print("Highlighted text:", highlighted_text)